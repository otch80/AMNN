{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import random\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path='/home/eric/Documents/Hashtag-recommendation-for-social-images/image_text_hashtagging/datasets/image_text/preprocessed_data'\n",
    "training_filename =os.path.join(root_path,'training_data.txt')\n",
    "validation_filename = os.path.join(root_path,'validation_data.txt')\n",
    "image_features_filename = ('inception_image_name_to_features.h5')\n",
    "data_logs = np.genfromtxt(root_path+'/'+'data_parameters.log',\n",
    "                                  delimiter=' ', dtype='str')\n",
    "data_logs = dict(zip(data_logs[:, 0], data_logs[:, 1]))\n",
    "MAX_TOKEN_LENGTH = int(data_logs['max_caption_length:']) + 2\n",
    "IMG_FEATS = int(data_logs['IMG_FEATS:'])\n",
    "BOS = str(data_logs['BOS:'])\n",
    "EOS = str(data_logs['EOS:'])\n",
    "PAD = str(data_logs['PAD:'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training dataset...\n",
      "Loading validation dataset...\n"
     ]
    }
   ],
   "source": [
    "print('Loading training dataset...')\n",
    "train_data = pd.read_table(training_filename, delimiter='*')\n",
    "train_data = np.asarray(train_data,dtype=str)\n",
    "training_dataset = train_data\n",
    "\n",
    "print('Loading validation dataset...')\n",
    "validation_dataset = pd.read_table(validation_filename,delimiter='*')\n",
    "validation_dataset = np.asarray(validation_dataset, dtype=str)\n",
    "validation_dataset = validation_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading vocabulary...\n"
     ]
    }
   ],
   "source": [
    "print('Loading vocabulary...')\n",
    "word_to_id = pickle.load(open(os.path.join(root_path,'word_to_id.p'), 'rb'))\n",
    "id_to_word = pickle.load(open(os.path.join(root_path,'id_to_word.p'), 'rb'))\n",
    "VOCABULARY_SIZE = len(word_to_id)\n",
    "word_to_id = word_to_id\n",
    "id_to_word = id_to_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_names_to_features = h5py.File(os.path.join(root_path,image_features_filename), 'r')\n",
    "data = training_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets=data[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "heaven earth follow\n"
     ]
    }
   ],
   "source": [
    "print(tweets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/eric/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "/home/eric/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/eric/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "max_words = 5000\n",
    "tokenizer = Tokenizer(num_words=max_words, lower=True)\n",
    "tokenizer.fit_on_texts(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 180\n",
    "def get_features(text_series):\n",
    "    \"\"\"\n",
    "    transforms text data to feature_vectors that can be used in the ml model.\n",
    "    tokenizer must be available.\n",
    "    \"\"\"\n",
    "    sequences = tokenizer.texts_to_sequences(text_series)\n",
    "    return pad_sequences(sequences, maxlen=maxlen)\n",
    "tweets_vec = get_features(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0 2490   32   85    4    5  316  258   17]\n"
     ]
    }
   ],
   "source": [
    "print(tweets_vec[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=16\n",
    "def make_empty_batch():\n",
    "    captions_batch = np.zeros((BATCH_SIZE,MAX_TOKEN_LENGTH,\n",
    "                                    VOCABULARY_SIZE))\n",
    "    images_batch = np.zeros((BATCH_SIZE, MAX_TOKEN_LENGTH,\n",
    "                                    IMG_FEATS))\n",
    "    tweets_batch=np.zeros((BATCH_SIZE,maxlen))\n",
    "    targets_batch = np.zeros((BATCH_SIZE,MAX_TOKEN_LENGTH,\n",
    "                                    VOCABULARY_SIZE))\n",
    "    return captions_batch, images_batch , targets_batch,tweets_batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_one_hot_target(one_hot_caption):\n",
    "    one_hot_target = np.zeros_like(one_hot_caption)\n",
    "    one_hot_target[:-1, :] = one_hot_caption[1:, :]\n",
    "    return one_hot_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrap_in_dictionary(one_hot_caption,image_features,tweets,\n",
    "                           one_hot_target):\n",
    "\n",
    "        return [{'text': one_hot_caption,\n",
    "                'image': image_features,\n",
    "                'tweets':tweets\n",
    "                },\n",
    "                {'output': one_hot_target}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_to_one_hot(caption):\n",
    "        tokenized_caption = caption.split()\n",
    "     #   tokenized_caption = [self.BOS] + tokenized_caption + [self.EOS]\n",
    "        tokenized_caption = [BOS] + tokenized_caption\n",
    "        #print(tokenized_caption)\n",
    "        one_hot_caption = np.zeros((MAX_TOKEN_LENGTH,\n",
    "                                    VOCABULARY_SIZE))\n",
    "        word_ids = [word_to_id[word] for word in tokenized_caption\n",
    "                        if word in word_to_id]\n",
    "        for sequence_arg, word_id in enumerate(word_ids):\n",
    "            one_hot_caption[sequence_arg,word_id] = 1\n",
    "        return one_hot_caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_features( image_name):\n",
    "    image_features = image_names_to_features[image_name]\\\n",
    "                                            ['image_features'][:]\n",
    "    image_input = np.zeros((MAX_TOKEN_LENGTH, IMG_FEATS))\n",
    "        # print(self.IMG_FEATS)\n",
    "        # print(image_features.shape)\n",
    "    for i in range(MAX_TOKEN_LENGTH):\n",
    "        image_input[i,:] =  image_features\n",
    "    return image_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 72, 1001)\n",
      "(16, 72, 2048)\n",
      "(16, 180)\n",
      "(16, 72, 1001)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "image_names = data[:,0].tolist()\n",
    "empty_batch = make_empty_batch()\n",
    "captions_batch = empty_batch[0]\n",
    "images_batch = empty_batch[1]\n",
    "targets_batch = empty_batch[2]\n",
    "tweets_batch=empty_batch[3]\n",
    "batch_counter = 0\n",
    "\n",
    "for data_arg, image_name in enumerate(image_names):\n",
    "    caption = data[data_arg,1]\n",
    "                #print(caption)\n",
    "    one_hot_caption = format_to_one_hot(caption)\n",
    "    captions_batch[batch_counter, :, :] = one_hot_caption\n",
    "    targets_batch[batch_counter, :, :]  = get_one_hot_target(\n",
    "                                                            one_hot_caption)\n",
    "    images_batch[batch_counter, :, :]   = get_image_features(\n",
    "                                                            image_name)\n",
    "    tweets_batch[batch_counter,:]=tweets_vec[data_arg]\n",
    "\n",
    "    if batch_counter == BATCH_SIZE - 1:\n",
    "        yield_dictionary = wrap_in_dictionary(captions_batch,images_batch,tweets_batch,\n",
    "                                                                targets_batch)\n",
    "#         print(yield_dictionary)\n",
    "        print(yield_dictionary[0]['text'].shape)\n",
    "        print(yield_dictionary[0]['image'].shape)\n",
    "        print(yield_dictionary[0]['tweets'].shape)\n",
    "        print(yield_dictionary[1]['output'].shape)\n",
    "        break\n",
    "        empty_batch = make_empty_batch()\n",
    "        captions_batch = empty_batch[0]\n",
    "        images_batch = empty_batch[1]\n",
    "        targets_batch = empty_batch[2]\n",
    "        tweets_batch=empty_batch[3]\n",
    "        batch_counter = 0\n",
    "\n",
    "    batch_counter = batch_counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
